{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x238d8c72600>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists in 'hymenoptera_data'. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory to download and extract the dataset\n",
    "data_dir = 'hymenoptera_data'\n",
    "zip_path = os.path.join(data_dir, 'hymenoptera_data.zip')\n",
    "\n",
    "# Check if the dataset has already been downloaded and extracted\n",
    "if not os.path.exists(data_dir):\n",
    "    # If the directory does not exist, create it\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # Download the dataset zip file\n",
    "    url = 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'\n",
    "    print(\"Downloading the dataset...\")\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "\n",
    "    # Unzip the dataset into the specified directory\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "\n",
    "    # Remove the zip file after extraction to save space\n",
    "    os.remove(zip_path)\n",
    "\n",
    "    print(f\"Dataset downloaded and extracted to '{data_dir}'\")\n",
    "else:\n",
    "    print(f\"Dataset already exists in '{data_dir}'. Skipping download.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\mihir/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:21<00:00, 2.21MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.4822 Acc: 0.7418\n",
      "val Loss: 0.1985 Acc: 0.9281\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5296 Acc: 0.7910\n",
      "val Loss: 0.3357 Acc: 0.8693\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5177 Acc: 0.7869\n",
      "val Loss: 0.3815 Acc: 0.8170\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5188 Acc: 0.7992\n",
      "val Loss: 0.4918 Acc: 0.8301\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4603 Acc: 0.7787\n",
      "val Loss: 0.3100 Acc: 0.8889\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.6975 Acc: 0.7418\n",
      "val Loss: 0.8011 Acc: 0.7451\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.5644 Acc: 0.7910\n",
      "val Loss: 0.2775 Acc: 0.9085\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3742 Acc: 0.8648\n",
      "val Loss: 0.2538 Acc: 0.9150\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3245 Acc: 0.8811\n",
      "val Loss: 0.2897 Acc: 0.8954\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3732 Acc: 0.8525\n",
      "val Loss: 0.2737 Acc: 0.9216\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.2749 Acc: 0.8934\n",
      "val Loss: 0.2168 Acc: 0.9346\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3057 Acc: 0.8525\n",
      "val Loss: 0.2149 Acc: 0.9281\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3276 Acc: 0.8607\n",
      "val Loss: 0.2096 Acc: 0.9216\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2893 Acc: 0.9016\n",
      "val Loss: 0.2017 Acc: 0.9281\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2844 Acc: 0.8811\n",
      "val Loss: 0.2113 Acc: 0.9281\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2533 Acc: 0.8893\n",
      "val Loss: 0.2291 Acc: 0.9281\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2915 Acc: 0.8689\n",
      "val Loss: 0.2300 Acc: 0.9281\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2188 Acc: 0.8975\n",
      "val Loss: 0.2490 Acc: 0.9216\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2162 Acc: 0.9139\n",
      "val Loss: 0.2123 Acc: 0.9346\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.3138 Acc: 0.8730\n",
      "val Loss: 0.2005 Acc: 0.9150\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2802 Acc: 0.8770\n",
      "val Loss: 0.2083 Acc: 0.9346\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2549 Acc: 0.8934\n",
      "val Loss: 0.2341 Acc: 0.9281\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2718 Acc: 0.8648\n",
      "val Loss: 0.2048 Acc: 0.9216\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2693 Acc: 0.8770\n",
      "val Loss: 0.2291 Acc: 0.9281\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2855 Acc: 0.8852\n",
      "val Loss: 0.2145 Acc: 0.9216\n",
      "\n",
      "Training complete in 22m 21s\n",
      "Best val Acc: 0.934641\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.5584 Acc: 0.6680\n",
      "val Loss: 0.3281 Acc: 0.8497\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5618 Acc: 0.7459\n",
      "val Loss: 0.1719 Acc: 0.9346\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.3883 Acc: 0.8197\n",
      "val Loss: 0.2604 Acc: 0.9085\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5427 Acc: 0.7910\n",
      "val Loss: 0.5863 Acc: 0.7843\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4777 Acc: 0.8156\n",
      "val Loss: 0.1923 Acc: 0.9412\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.5313 Acc: 0.7869\n",
      "val Loss: 0.1573 Acc: 0.9542\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3987 Acc: 0.8115\n",
      "val Loss: 0.1677 Acc: 0.9412\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3141 Acc: 0.8730\n",
      "val Loss: 0.1641 Acc: 0.9477\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.4130 Acc: 0.8484\n",
      "val Loss: 0.1712 Acc: 0.9412\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3610 Acc: 0.8279\n",
      "val Loss: 0.1736 Acc: 0.9412\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3828 Acc: 0.8361\n",
      "val Loss: 0.1676 Acc: 0.9542\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3466 Acc: 0.8484\n",
      "val Loss: 0.1514 Acc: 0.9608\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3609 Acc: 0.8443\n",
      "val Loss: 0.1750 Acc: 0.9477\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.3599 Acc: 0.8238\n",
      "val Loss: 0.1622 Acc: 0.9477\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3835 Acc: 0.8361\n",
      "val Loss: 0.1652 Acc: 0.9412\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2814 Acc: 0.8730\n",
      "val Loss: 0.1675 Acc: 0.9542\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.3136 Acc: 0.8730\n",
      "val Loss: 0.1756 Acc: 0.9477\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2767 Acc: 0.8770\n",
      "val Loss: 0.1625 Acc: 0.9477\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.3392 Acc: 0.8443\n",
      "val Loss: 0.1701 Acc: 0.9477\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.3257 Acc: 0.8443\n",
      "val Loss: 0.1667 Acc: 0.9542\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.3445 Acc: 0.8607\n",
      "val Loss: 0.1719 Acc: 0.9477\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.3619 Acc: 0.8197\n",
      "val Loss: 0.1844 Acc: 0.9477\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2653 Acc: 0.8811\n",
      "val Loss: 0.1540 Acc: 0.9542\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.3484 Acc: 0.8320\n",
      "val Loss: 0.1729 Acc: 0.9477\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3861 Acc: 0.8238\n",
      "val Loss: 0.1763 Acc: 0.9477\n",
      "\n",
      "Training complete in 13m 34s\n",
      "Best val Acc: 0.960784\n"
     ]
    }
   ],
   "source": [
    "model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Model Training Accuracy: 98.77%\n",
      "Fine-Tuned Model Validation Accuracy: 93.46%\n",
      "Feature Extractor Model Training Accuracy: 92.62%\n",
      "Feature Extractor Model Validation Accuracy: 96.08%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Turn off gradients for validation, saves memory and computations\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)  # Send inputs to the device (GPU or CPU)\n",
    "            labels = labels.to(device)  # Send labels to the device\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class with max probability\n",
    "            \n",
    "            total += labels.size(0)  # Update the total number of samples\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "            \n",
    "    accuracy = 100 * correct / total  # Calculate accuracy percentage\n",
    "    return accuracy\n",
    "\n",
    "# Report accuracy for Fine-Tuned Model\n",
    "train_acc_ft = evaluate_model(model_ft, dataloaders['train'])\n",
    "val_acc_ft = evaluate_model(model_ft, dataloaders['val'])\n",
    "print(f'Fine-Tuned Model Training Accuracy: {train_acc_ft:.2f}%')\n",
    "print(f'Fine-Tuned Model Validation Accuracy: {val_acc_ft:.2f}%')\n",
    "\n",
    "# Report accuracy for Feature Extractor Model\n",
    "train_acc_fe = evaluate_model(model_conv, dataloaders['train'])\n",
    "val_acc_fe = evaluate_model(model_conv, dataloaders['val'])\n",
    "print(f'Feature Extractor Model Training Accuracy: {train_acc_fe:.2f}%')\n",
    "print(f'Feature Extractor Model Validation Accuracy: {val_acc_fe:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
